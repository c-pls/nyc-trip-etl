{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/12/03 22:07:46 WARN Utils: Your hostname, cpPC resolves to a loopback address: 127.0.1.1; using 172.25.249.11 instead (on interface eth0)\n",
      "23/12/03 22:07:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/12/03 22:07:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Read S3 File\")\n",
    "    .master(\"spark://localhost:7077\")\n",
    "    .config(\n",
    "        \"spark.jars\",\n",
    "        \"/opt/bitnami/spark/jars/hadoop-aws-3.3.4.jar,/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.12.262.jar\",\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(1000).toDF(\"number\")\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read\n",
    "taxi_zone_df = (\n",
    "    spark.read.option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"s3a://de-666ne92p/tmp/taxi+_zone_lookup.csv\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zone_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "date_dim_df = (\n",
    "    spark.read.option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"s3a://de-666ne92p/tmp/date_dim.csv\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+--------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "|date_key|      date|day_of_week|day_name|day_of_month|day_of_year|week_of_year|month|month_name|quarter|year|is_holiday|is_weekend|is_workday|\n",
      "+--------+----------+-----------+--------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "|   10957|2000-01-01|          6|Saturday|          31|          1|          52|    1|   January|      1|2000|      true|      true|     false|\n",
      "|   10958|2000-01-02|          0|  Sunday|          31|          2|          52|    1|   January|      1|2000|     false|      true|     false|\n",
      "+--------+----------+-----------+--------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "date_dim_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimention_df():\n",
    "    def taxi_zone_df():\n",
    "        return (\n",
    "            spark.read.option(\"inferSchema\", \"true\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .csv(\"s3a://de-666ne92p/tmp/taxi+_zone_lookup.csv\")\n",
    "            .cache()\n",
    "        )\n",
    "\n",
    "    def date_dim_df():\n",
    "        return (\n",
    "            spark.read.option(\"inferSchema\", \"true\")\n",
    "            .option(\"header\", \"true\")\n",
    "            .csv(\"s3a://de-666ne92p/tmp/date_dim.csv\")\n",
    "            .cache()\n",
    "        )\n",
    "\n",
    "    def vendor_df():\n",
    "        schema = StructType(\n",
    "            [\n",
    "                StructField(\"VENDOR_KEY\", IntegerType(), True),\n",
    "                StructField(\"VENDOR_ID\", IntegerType(), True),\n",
    "                StructField(\"VENDOR_NAME\", StringType(), True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Your CSV-like data\n",
    "        data = [(1, 1, \"Creative Mobile Technologies, LLC\"),\n",
    "                (2, 2, \"VeriFone Inc.\")]\n",
    "\n",
    "        # Create a DataFrame\n",
    "        return spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "    def trip_type_df():\n",
    "        schema = StructType(\n",
    "            [\n",
    "                StructField(\"TRIP_TYPE_KEY\", IntegerType(), True),\n",
    "                StructField(\"TRIP_TYPE_ID\", IntegerType(), True),\n",
    "                StructField(\"TRIP_TYPE_NAME\", StringType(), True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        data = [(1, 1, \"Street-hail\"), (2, 2, \"Dispatch\")]\n",
    "\n",
    "        return spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "    def rate_code_df():\n",
    "        schema = StructType(\n",
    "            [\n",
    "                StructField(\"RATE_CODE_KEY\", IntegerType(), True),\n",
    "                StructField(\"RATE_CODE_ID\", IntegerType(), True),\n",
    "                StructField(\"RATE_CODE_EFFECT\", StringType(), True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        data = [\n",
    "            (1, 1, \"Standard rate\"),\n",
    "            (2, 2, \"JFK\"),\n",
    "            (3, 3, \"Newark\"),\n",
    "            (4, 4, \"Nassau or Westchester\"),\n",
    "            (5, 5, \"Negotiated fare\"),\n",
    "            (6, 6, \"Group ride\"),\n",
    "        ]\n",
    "\n",
    "        return spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "    def payment_type_df():\n",
    "        schema = StructType(\n",
    "            [\n",
    "                StructField(\"PAYMENT_TYPE_KEY\", IntegerType(), True),\n",
    "                StructField(\"PAYMENT_TYPE_ID\", IntegerType(), True),\n",
    "                StructField(\"PAYMENT_TYPE_NAME\", StringType(), True),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        data = [\n",
    "            (1, 1, \"Credit card\"),\n",
    "            (2, 2, \"Cash\"),\n",
    "            (3, 3, \"No charge\"),\n",
    "            (4, 4, \"Dispute\"),\n",
    "            (5, 5, \"Unknown\"),\n",
    "            (6, 6, \"Voided trip\"),\n",
    "        ]\n",
    "\n",
    "        return spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "    return taxi_zone_df(), date_dim_df(), vendor_df(), trip_type_df(), rate_code_df(), payment_type_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 22:32:31 WARN CacheManager: Asked to cache already cached data.        \n",
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/03 22:32:37 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    taxi_zone_df,\n",
    "    date_dim_df,\n",
    "    vendor_df,\n",
    "    trip_type_df,\n",
    "    rate_code_df,\n",
    "    payment_type_df,\n",
    ") = dimention_df()\n",
    "\n",
    "taxi_zone_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "|date_key|      date|day_of_week| day_name|day_of_month|day_of_year|week_of_year|month|month_name|quarter|year|is_holiday|is_weekend|is_workday|\n",
      "+--------+----------+-----------+---------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "|   10957|2000-01-01|          6| Saturday|          31|          1|          52|    1|   January|      1|2000|      true|      true|     false|\n",
      "|   10958|2000-01-02|          0|   Sunday|          31|          2|          52|    1|   January|      1|2000|     false|      true|     false|\n",
      "|   10959|2000-01-03|          1|   Monday|          31|          3|           1|    1|   January|      1|2000|     false|     false|      true|\n",
      "|   10960|2000-01-04|          2|  Tuesday|          31|          4|           1|    1|   January|      1|2000|     false|     false|      true|\n",
      "|   10961|2000-01-05|          3|Wednesday|          31|          5|           1|    1|   January|      1|2000|     false|     false|      true|\n",
      "+--------+----------+-----------+---------+------------+-----------+------------+-----+----------+-------+----+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_dim_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+\n",
      "|VENDOR_KEY|VENDOR_ID|         VENDOR_NAME|\n",
      "+----------+---------+--------------------+\n",
      "|         1|        1|Creative Mobile T...|\n",
      "|         2|        2|       VeriFone Inc.|\n",
      "+----------+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vendor_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------------+\n",
      "|TRIP_TYPE_KEY|TRIP_TYPE_ID|TRIP_TYPE_NAME|\n",
      "+-------------+------------+--------------+\n",
      "|            1|           1|   Street-hail|\n",
      "|            2|           2|      Dispatch|\n",
      "+-------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_type_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+--------------------+\n",
      "|RATE_CODE_KEY|RATE_CODE_ID|    RATE_CODE_EFFECT|\n",
      "+-------------+------------+--------------------+\n",
      "|            1|           1|       Standard rate|\n",
      "|            2|           2|                 JFK|\n",
      "|            3|           3|              Newark|\n",
      "|            4|           4|Nassau or Westche...|\n",
      "|            5|           5|     Negotiated fare|\n",
      "+-------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rate_code_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+-----------------+\n",
      "|PAYMENT_TYPE_KEY|PAYMENT_TYPE_ID|PAYMENT_TYPE_NAME|\n",
      "+----------------+---------------+-----------------+\n",
      "|               1|              1|      Credit card|\n",
      "|               2|              2|             Cash|\n",
      "|               3|              3|        No charge|\n",
      "|               4|              4|          Dispute|\n",
      "|               5|              5|          Unknown|\n",
      "+----------------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_type_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
